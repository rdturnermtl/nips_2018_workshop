\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2018

% ready for submission
\usepackage{nips_2018}

% to compile a preprint version, e.g., for submission to arXiv, add
% add the [preprint] option:
% \usepackage[preprint]{nips_2018}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2018}

% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2018}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\title{Formatting instructions for NIPS 2018}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  David S.~Hippocampus\thanks{Use footnote for providing further
    information about author (webpage, alternative
    address)---\emph{not} for acknowledging funding agencies.} \\
  Department of Computer Science\\
  Cranberry-Lemon University\\
  Pittsburgh, PA 15213 \\
  \texttt{hippo@cs.cranberry-lemon.edu} \\
  %% examples of more authors
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

% Motivation
Rigourous design of machine learning competitions is at least as difficult as rigrouous design of experiments.
It is an experiment across comparing multiple machine learning algorithms (possibly with adversarial agents)\@.
Part of experimental design involves proper analysis with confidence intervals (error bars) and statistical tests.

% TODO look for citation show frequency
Surprisingly adding error bars and significance levels has been rarer in machine learning than other parts of science.
This is somewhat surprising given that machine learning methodology is often based upon statistics.
Many comptetitions and benchmark data sets follow a plateau like ``leader board'' with big gains at first followed by a long period of very small gains.
Once these gains become very small and incremental it is easy for these gains to be explainable purely by noise.

One of the obstacles inhibiting widespread use of these statistical methods is tools that introduce minimal time overhead in use.
Indeed many other areas have tools that standardize the analysis.  % TODO reword
Benchmark tools is designed to modular.
However, it can be called in a simple all one call fasion using a dictionary of sklearn compatible objects and a train and test data set.
The routine will train, test, and benchmark the models on multiple loss functions.

Considering multiple loss functions is a crucuial part of the package.
Often challenges and analysis are based upon a single somewhat arbitrary loss function; and developers may become obsessed with incremental improvements in a single metric.
Therefore, we allow a single model to be benchmarked according to multiple metrics.
However, a crucial piece of this is that the benchmark tools package supports the Bayes' decision rule calculation that can convert a predictive distribution into an action.
Indeed the classic example for regression is for MSE one should report the mean of the predictive distribution while for MAE one should report the median.
This conversion is done automatically within the package and is essential if one wants to ensure a single model is being benchmarked fairly and consistently across multiple metrics.

% Less repetetive, easy to add CIs, stat sig
% Why useful for challenges

% Workflow: from sklean dict
% Figure

% Tasks: classificatio and reg

% How math in each works
% proper scoring rules
% error bars, and how stat matches

% A note on unit tests

% sciprint
% principles on correct formatting

% Can copy over examples from README

% refs: proper scoring, AUPRG, bernstein
% sklearn bug

% include URL

\end{document}
